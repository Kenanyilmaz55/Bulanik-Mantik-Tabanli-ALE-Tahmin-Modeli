# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sf5S7dWLLGSXGSjYoQy_gJb9bafyW97d
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def load_and_analyze_csv(file_path='veri.csv'):
    """
    CSV dosyasÄ±nÄ± yÃ¼kle ve detaylÄ± analiz yap
    """
    try:
        # CSV dosyasÄ±nÄ± yÃ¼kle
        print("CSV dosyasÄ± yÃ¼kleniyor...")
        data = pd.read_csv(file_path)

        print(f"âœ“ Veri baÅŸarÄ±yla yÃ¼klendi!")
        print(f"  - Boyut: {data.shape[0]} satÄ±r Ã— {data.shape[1]} sÃ¼tun")

        # SÃ¼tun isimlerini kontrol et ve standartlaÅŸtÄ±r
        print(f"\nSÃ¼tun isimleri:")
        for i, col in enumerate(data.columns):
            print(f"  {i+1}. {col}")

        # EÄŸer sÃ¼tun isimleri farklÄ±ysa standart isimleri ata
        expected_columns = ['anchor_ratio', 'transmission_range', 'node_density', 'iteration_count', 'ALE', 'std_dev']

        if len(data.columns) == 6:
            data.columns = expected_columns
            print(f"\nâœ“ SÃ¼tun isimleri standartlaÅŸtÄ±rÄ±ldÄ±")
        elif len(data.columns) == 5:
            # Standart sapma sÃ¼tunu yoksa
            data.columns = expected_columns[:-1]
            print(f"\nâœ“ SÃ¼tun isimleri standartlaÅŸtÄ±rÄ±ldÄ± (standart sapma sÃ¼tunu yok)")

        # Veri tiplerini kontrol et
        print(f"\nVeri tipleri:")
        print(data.dtypes)

        # Temel istatistikler
        print(f"\nTemel Ä°statistikler:")
        print(data.describe())

        # Eksik deÄŸer kontrolÃ¼
        missing_values = data.isnull().sum()
        if missing_values.any():
            print(f"\nâš ï¸  Eksik deÄŸerler tespit edildi:")
            for col, count in missing_values.items():
                if count > 0:
                    print(f"  - {col}: {count} eksik deÄŸer")

            # Eksik deÄŸerleri doldur
            print(f"\nğŸ“Š Eksik deÄŸerler ortalama ile doldurulacak...")
            data = data.fillna(data.mean())
            print(f"âœ“ Eksik deÄŸerler dolduruldu")
        else:
            print(f"\nâœ“ Eksik deÄŸer bulunmuyor")

        # AykÄ±rÄ± deÄŸer kontrolÃ¼
        print(f"\nğŸ” AykÄ±rÄ± deÄŸer kontrolÃ¼:")
        for col in data.select_dtypes(include=[np.number]).columns:
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]
            if len(outliers) > 0:
                print(f"  - {col}: {len(outliers)} aykÄ±rÄ± deÄŸer tespit edildi")
            else:
                print(f"  - {col}: AykÄ±rÄ± deÄŸer yok")

        # Korelasyon analizi
        print(f"\nğŸ“ˆ Korelasyon Analizi:")
        correlation_matrix = data.corr()
        print(correlation_matrix.round(3))

        # GÃ¶rselleÅŸtirme
        create_data_visualizations(data)

        return data.values, data

    except FileNotFoundError:
        print(f"âŒ Hata: '{file_path}' dosyasÄ± bulunamadÄ±!")
        print("LÃ¼tfen dosya yolunu kontrol edin veya dosyayÄ± doÄŸru konuma yerleÅŸtirin.")
        return None, None

    except Exception as e:
        print(f"âŒ Veri yÃ¼kleme hatasÄ±: {str(e)}")
        return None, None

def create_data_visualizations(data):
    """
    Veri seti iÃ§in gÃ¶rselleÅŸtirmeler oluÅŸtur
    """
    print(f"\nğŸ¨ GÃ¶rselleÅŸtirmeler oluÅŸturuluyor...")

    # Figure boyutunu ayarla
    plt.style.use('default')

    # 1. Veri daÄŸÄ±lÄ±mlarÄ±
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('WSN Veri Seti - Ã–zellik DaÄŸÄ±lÄ±mlarÄ±', fontsize=16, fontweight='bold')

    feature_names = ['Ã‡apa OranÄ±', 'Ä°letim AralÄ±ÄŸÄ±', 'DÃ¼ÄŸÃ¼m YoÄŸunluÄŸu', 'Yineleme SayÄ±sÄ±', 'ALE']

    for i, (col, name) in enumerate(zip(data.columns[:5], feature_names)):
        row = i // 3
        col_idx = i % 3

        axes[row, col_idx].hist(data[col], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axes[row, col_idx].set_title(f'{name} DaÄŸÄ±lÄ±mÄ±')
        axes[row, col_idx].set_xlabel(name)
        axes[row, col_idx].set_ylabel('Frekans')
        axes[row, col_idx].grid(True, alpha=0.3)

        # Ä°statistikleri ekle
        mean_val = data[col].mean()
        std_val = data[col].std()
        axes[row, col_idx].axvline(mean_val, color='red', linestyle='--',
                                  label=f'Ortalama: {mean_val:.3f}')
        axes[row, col_idx].legend()

    # Son subplot'u gizle
    axes[1, 2].set_visible(False)

    plt.tight_layout()
    plt.show()

    # 2. Korelasyon matrisi heatmap
    plt.figure(figsize=(10, 8))
    correlation_matrix = data.corr()

    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm',
                center=0, square=True, fmt='.3f', cbar_kws={"shrink": .8})
    plt.title('Ã–zellikler ArasÄ± Korelasyon Matrisi', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()

    # 3. ALE ile diÄŸer Ã¶zellikler arasÄ±ndaki iliÅŸki
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ALE ile GiriÅŸ Ã–zellikleri ArasÄ±ndaki Ä°liÅŸki', fontsize=16, fontweight='bold')

    input_features = data.columns[:4]
    feature_names = ['Ã‡apa OranÄ±', 'Ä°letim AralÄ±ÄŸÄ±', 'DÃ¼ÄŸÃ¼m YoÄŸunluÄŸu', 'Yineleme SayÄ±sÄ±']

    for i, (feature, name) in enumerate(zip(input_features, feature_names)):
        row = i // 2
        col = i % 2

        axes[row, col].scatter(data[feature], data['ALE'], alpha=0.6, color='blue')
        axes[row, col].set_xlabel(name)
        axes[row, col].set_ylabel('ALE')
        axes[row, col].set_title(f'{name} vs ALE')
        axes[row, col].grid(True, alpha=0.3)

        # Trend Ã§izgisi ekle
        z = np.polyfit(data[feature], data['ALE'], 1)
        p = np.poly1d(z)
        axes[row, col].plot(data[feature], p(data[feature]), "r--", alpha=0.8)

        # Korelasyon katsayÄ±sÄ±nÄ± gÃ¶ster
        corr_coef = data[feature].corr(data['ALE'])
        axes[row, col].text(0.05, 0.95, f'r = {corr_coef:.3f}',
                           transform=axes[row, col].transAxes,
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))

    plt.tight_layout()
    plt.show()

    print("âœ“ GÃ¶rselleÅŸtirmeler tamamlandÄ±")

def validate_data_format(data):
    """
    Veri formatÄ±nÄ± doÄŸrula
    """
    print(f"\nğŸ” Veri formatÄ± doÄŸrulanÄ±yor...")

    if data is None:
        print("âŒ Veri yÃ¼klenemedi!")
        return False

    # Beklenen format: 107 satÄ±r, 5 veya 6 sÃ¼tun
    expected_rows = 107
    min_cols = 5
    max_cols = 6

    actual_rows, actual_cols = data.shape

    print(f"  - Beklenen satÄ±r sayÄ±sÄ±: {expected_rows}")
    print(f"  - GerÃ§ek satÄ±r sayÄ±sÄ±: {actual_rows}")
    print(f"  - Beklenen sÃ¼tun sayÄ±sÄ±: {min_cols}-{max_cols}")
    print(f"  - GerÃ§ek sÃ¼tun sayÄ±sÄ±: {actual_cols}")

    if actual_rows != expected_rows:
        print(f"âš ï¸  UyarÄ±: SatÄ±r sayÄ±sÄ± beklenenden farklÄ±!")

    if actual_cols < min_cols or actual_cols > max_cols:
        print(f"âŒ Hata: SÃ¼tun sayÄ±sÄ± beklenen aralÄ±kta deÄŸil!")
        return False

    # Veri tiplerini kontrol et
    numeric_data = data.select_dtypes(include=[np.number])
    if len(numeric_data.columns) != len(data.columns):
        print(f"âš ï¸  UyarÄ±: TÃ¼m sÃ¼tunlar sayÄ±sal deÄŸil!")

    print(f"âœ“ Veri formatÄ± doÄŸrulandÄ±")
    return True

def prepare_data_for_fuzzy_system(data_array):
    """
    BulanÄ±k sistem iÃ§in veriyi hazÄ±rla
    """
    print(f"\nğŸ”§ Veri bulanÄ±k sistem iÃ§in hazÄ±rlanÄ±yor...")

    # Son sÃ¼tun standart sapma ise Ã§Ä±kar
    if data_array.shape[1] == 6:
        # Ä°lk 4 Ã¶zellik + ALE (standart sapma hariÃ§)
        processed_data = data_array[:, :5]
        print(f"âœ“ Standart sapma sÃ¼tunu Ã§Ä±karÄ±ldÄ±")
    else:
        processed_data = data_array

    print(f"âœ“ HazÄ±rlanan veri boyutu: {processed_data.shape}")
    print(f"  - GiriÅŸ Ã¶zellikleri: {processed_data.shape[1]-1}")
    print(f"  - Ã‡Ä±kÄ±ÅŸ deÄŸiÅŸkeni: 1 (ALE)")

    return processed_data

# Test fonksiyonu
if __name__ == "__main__":
    print("=" * 60)
    print("WSN VERÄ° SETÄ° YÃœKLEME VE ANALÄ°Z MODÃœLÃœ")
    print("=" * 60)

    # Veri yÃ¼kleme ve analizi
    data_array, data_df = load_and_analyze_csv('veri.csv')

    if data_array is not None:
        # Veri formatÄ±nÄ± doÄŸrula
        valid = validate_data_format(data_df)

        if valid:
            # BulanÄ±k sistem iÃ§in hazÄ±rla
            processed_data = prepare_data_for_fuzzy_system(data_array)
            print(f"\nâœ… Veri baÅŸarÄ±yla yÃ¼klendi ve iÅŸlendi!")
            print(f"   BulanÄ±k sisteme hazÄ±r veri boyutu: {processed_data.shape}")
        else:
            print(f"\nâŒ Veri formatÄ± uygun deÄŸil!")
    else:
        print(f"\nâŒ Veri yÃ¼klenemedi!")