# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sf5S7dWLLGSXGSjYoQy_gJb9bafyW97d
"""

import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1) Veri setini yÃ¼kle ve ansaliz et
df = pd.read_csv("veri.csv")
print("=== VERÄ° ANALÄ°ZÄ° ===")
print("Veri seti boyutu:", df.shape)
print("\nDeÄŸiÅŸkenlerin istatistikleri:")
print(df.describe())
# 2 Ã¼stÃ¼ndeki ale deÄŸerlerini sutundan Ã§Ä±kar
df = df[df['ale'] < 2]
print("\nDeÄŸiÅŸkenler arasÄ± korelasyon (ALE ile):")
correlations = df.corr()['ale'].drop('ale').sort_values(key=abs, ascending=False)
print(correlations)

# 2) Ãœyelik fonksiyonlarÄ±
def triangular(x, a, b, c):
    """ÃœÃ§gen Ã¼yelik fonksiyonu"""
    return np.maximum(np.minimum((x - a) / (b - a + 1e-9), (c - x) / (c - b + 1e-9)), 0)

def gaussian(x, mu, sigma):
    """Gauss Ã¼yelik fonksiyonu"""
    return np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))

def trapezoidal(x, a, b, c, d):
    """Yamuk Ã¼yelik fonksiyonu"""
    return np.maximum(np.minimum(np.minimum((x - a) / (b - a + 1e-9), 1), (d - x) / (d - c + 1e-9)), 0)

# 3) Veri analizi sonuÃ§larÄ±na gÃ¶re Ã¶zelleÅŸtirilmiÅŸ Ã¼yelik fonksiyonlarÄ±

# VERÄ° ANALÄ°ZÄ° SONUÃ‡LARI:
# anchor_ratio: 10-30 arasÄ±, Ã§oÄŸu 15-30 arasÄ±nda
# trans_range: 12-25 arasÄ±, Ã§oÄŸu 15-20 arasÄ±nda
# node_density: 100, 200, 300 deÄŸerleri (kategorik gibi)
# iterations: 14-100 arasÄ±, geniÅŸ daÄŸÄ±lÄ±m
# ale: 0.39-2.57 arasÄ±, ortalama ~1.0
optimized_triangular = {
    "anchor_ratio": {
        "low":    lambda x: triangular(x, 7.0, 15.0, 18.0),
        "medium": lambda x: triangular(x, 15.0, 18.0, 30.0),
        "high":   lambda x: triangular(x, 18.0, 30.0, 33.0),
    },  # sharp_trapezoidal - sharp_trapezoidal seÃ§ildi
    "trans_range": {
        "low":    lambda x: triangular(x, 10.1, 15.0, 17.0),
        "medium": lambda x: triangular(x, 15.0, 17.0, 20.0),
        "high":   lambda x: triangular(x, 17.0, 20.0, 26.9),
    },  # sharp_trapezoidal - sharp_trapezoidal seÃ§ildi
    "node_density": {
        "low":    lambda x: triangular(x, 70.0, 100.0, 200.0),
        "medium": lambda x: triangular(x, 100.0, 200.0, 300.0),
        "high":   lambda x: triangular(x, 200.0, 300.0, 330.0),
    },  # sharp_trapezoidal - sharp_trapezoidal seÃ§ildi
    "iterations": {
        "low":    lambda x: triangular(x, 1.1, 30.0, 40.0),
        "medium": lambda x: triangular(x, 30.0, 40.0, 70.0),
        "high":   lambda x: triangular(x, 40.0, 70.0, 112.9),
    },  # sharp_trapezoidal - sharp_trapezoidal seÃ§ildi


    "ale": {
        "low": lambda x: triangular(x, 0.2, 0.7, 0.9),
        "medium": lambda x: triangular(x, 0.9, 1.2, 1.6),
        "high": lambda x: triangular(x, 1.3, 2.1, 3),
    },
}

# Optimized Gaussian Membership Functions
optimized_gaussian = {
    "anchor_ratio": {
        "low": lambda x: gaussian(x, 14.6, 1.0),
        "medium": lambda x: gaussian(x, 20.0, 1.1),
        "high": lambda x: gaussian(x, 29.6, 1.5),
    },
    "trans_range": {
        "low": lambda x: gaussian(x, 15.3, 0.9),
        "medium": lambda x: gaussian(x, 19.7, 0.7),
        "high": lambda x: gaussian(x, 24.0, 1.0),
    },
    "node_density": {
        "low":    lambda x: triangular(x, 70.0, 100.0, 200.0),
        "medium": lambda x: triangular(x, 100.0, 200.0, 300.0),
        "high":   lambda x: triangular(x, 200.0, 300.0, 330.0),
    },  # sharp_trapezoidal - sharp_trapezoidal seÃ§ildi
    "iterations": {
        "low": lambda x: gaussian(x, 23.9, 7.8),
        "medium": lambda x: gaussian(x, 48.6, 10.8),
        "high": lambda x: gaussian(x, 81.7, 6.0),
    },
    "ale": {
        "low": lambda x: gaussian(x, 0.7, 0.2),
        "medium": lambda x: gaussian(x, 1.2, 0.3),
        "high": lambda x: gaussian(x, 1.8, 0.4),
    },
}
# Hibrit model - daha iyi performans iÃ§in
hybrid_optimized = {
   "anchor_ratio": {
    "low": lambda x: gaussian(x, 14.0, 1.2),      # Ana yoÄŸunluk bÃ¶lgesi 13-15
    "medium": lambda x: triangular(x, 16.0, 20.0, 26.0),  # Orta bÃ¶lge geniÅŸ tutuldu
    "high": lambda x: gaussian(x, 29.0, 1.0),     # YoÄŸunluk 28-30'da
    },
    "trans_range": {
    "low": lambda x: trapezoidal(x, 12.2, 13.8, 15.2, 16.8),   # Sol cluster
    "medium": lambda x: triangular(x, 16.5, 18.5, 20.5),       # Orta geÃ§iÅŸ
    "high": lambda x: trapezoidal(x, 20.0, 22.0, 23.5, 24.8),  # SaÄŸ cluster
    },
    "node_density": {
      "low": lambda x: trapezoidal(x, 80, 90, 110, 120),
      "medium": lambda x: trapezoidal(x, 180, 190, 210, 220),
      "high": lambda x: trapezoidal(x, 280, 290, 310, 320),

    },
    "iterations": {
        "low": lambda x: trapezoidal(x, 5.4, 21.5, 26.3, 36.3),
        "medium": lambda x: trapezoidal(x, 36.3, 43.8, 53.5, 65.2),
        "high": lambda x: trapezoidal(x, 65.2, 73.6, 89.9, 108.6),
    },
    "ale": {
        "low": lambda x: gaussian(x, 0.7, 0.2),
        "medium": lambda x: gaussian(x, 1.2, 0.3),
        "high": lambda x: gaussian(x, 1.6, 0.09),
    },

}
optimized_trapezoidal = {
    "anchor_ratio": {
        "low": lambda x: trapezoidal(x, 8.0, 13.2, 16.1, 17.3),
        "medium": lambda x: trapezoidal(x, 17.3, 18.0, 22.0, 24.8),
        "high": lambda x: trapezoidal(x, 24.8, 26.6, 32.5, 32.0),
    },
    "trans_range": {
        "low": lambda x: trapezoidal(x, 10.7, 13.8, 16.8, 17.5),
        "medium": lambda x: trapezoidal(x, 17.5, 17.7, 21.7, 21.8),
        "high": lambda x: trapezoidal(x, 21.8, 21.6, 26.4, 26.3),
    },
    "node_density": {
        "low": lambda x: trapezoidal(x, 80.0, 90.0, 110.0, 150.0),
        "medium": lambda x: trapezoidal(x, 150.0, 180.0, 220.0, 250.0),
        "high": lambda x: trapezoidal(x, 250.0, 270.0, 330.0, 320.0),
    },
    "iterations": {
        "low": lambda x: trapezoidal(x, 5.4, 21.5, 26.3, 36.3),
        "medium": lambda x: trapezoidal(x, 36.3, 43.8, 53.5, 65.2),
        "high": lambda x: trapezoidal(x, 65.2, 73.6, 89.9, 108.6),
    },
    "ale": {
        "low": lambda x: trapezoidal(x, 0.2, 0.6, 0.8, 0.9),
        "medium": lambda x: trapezoidal(x, 0.9, 1.1, 1.3, 1.6),
        "high": lambda x: trapezoidal(x, 1.6, 1.8, 2.3, 2.8),
    },
}
# ALE Ã§Ä±kÄ±ÅŸ deÄŸerleri - veri analizi sonuÃ§larÄ±na gÃ¶re

ale_centers = {"low": 0.5, "medium": 1.3, "high": 2.4}

ale_x = np.linspace(0.35, 2.6, 300)


# ALE Ã§Ä±kÄ±ÅŸ deÄŸerleri - veri analizi sonuÃ§larÄ±na gÃ¶re

# 4) GeliÅŸtirilmiÅŸ kural tabanÄ± - korelasyon analizi sonuÃ§larÄ±na gÃ¶re
# Korelasyon sonuÃ§larÄ±:
# iterations ile ALE arasÄ±nda negatif korelasyon (-0.46) - gÃ¼Ã§lÃ¼
# anchor_ratio ile ALE arasÄ±nda negatif korelasyon (-0.35) - orta
# node_density ile ALE arasÄ±nda negatif korelasyon (-0.30) - orta
# trans_range ile ALE arasÄ±nda pozitif korelasyon (0.44) - gÃ¼Ã§lÃ¼
enhanced_rules = [
    ({"node_density": "low", "iterations" : "low"}, "high", 5),
    ({"node_density": "low"}, "high", 2.3), # daha gÃ¼Ã§lÃ¼ kural
    ({"node_density": "medium"}, "low", 1.2),
    ({"node_density": "high"}, "low", 2.5),
    ({"iterations": "low"}, "high", 1.5),   # daha etkili
    ({"iterations": "medium"}, "low", 1.0),
    ({"iterations": "high"}, "low", 2.5),
    ({"anchor_ratio": "high"}, "low", 2.5),  # Ã¶nemli
    ({"anchor_ratio": "medium"}, "low", 1.0),
    ({"trans_range": "medium"}, "low", 1.0),
    ({"trans_range": "high"}, "low", 1.0),

    ({"anchor_ratio": "high", "node_density": "high"}, "low", 5.0),
    ({"iterations": "high", "node_density": "high"}, "low", 2.0),
    ({"iterations": "low", "node_density": "low"}, "high", 2.0),
    ({"anchor_ratio": "high", "trans_range": "high"}, "low", 1.0),
        # Kombine kurallar - yeni deÄŸiÅŸkenlerle
     ({"anchor_ratio": "low", "trans_range": "low"}, "low", 1.0),
    ({"anchor_ratio": "low", "trans_range": "medium"}, "high", 1.0),
    ({"anchor_ratio": "low", "anchor_ratio": "medium"}, "high", 1.0),

    #({}, "medium", 0.1),  # varsayÄ±lan kuralÄ±n etkisi azaltÄ±ldÄ±
]
# 5) GeliÅŸtirilmiÅŸ defuzzification yÃ¶ntemleri
def defuzz_centroid(activations, ale_mf_dict):
    """AÄŸÄ±rlÄ±k merkezi yÃ¶ntemi"""
    agg = np.zeros_like(ale_x)
    for term, act in activations.items():
        if act > 0:
            mf_vals = ale_mf_dict[term](ale_x)
            agg = np.maximum(agg, np.minimum(act, mf_vals))

    if agg.sum() == 0:
        return 1.2
    return np.sum(ale_x * agg) / agg.sum()

def defuzz_weighted_average(activations):
    """AÄŸÄ±rlÄ±klÄ± ortalama yÃ¶ntemi"""
    if not activations or sum(activations.values()) == 0:
        return 1.2

    num = sum(act * ale_centers[term] for term, act in activations.items() if act > 0)
    den = sum(act for act in activations.values() if act > 0)
    return num / den

def defuzz_center_of_sums(activations, ale_mf_dict):
    agg = np.zeros_like(ale_x)
    for term, act in activations.items():
        if act > 0:
            agg += ale_mf_dict[term](ale_x) * act
    if agg.sum() == 0:
        return 1.2
    return np.sum(ale_x * agg) / agg.sum()

def defuzz_max_membership(activations):
    """Maksimum Ã¼yelik yÃ¶ntemi"""
    if not activations:
        return 1.2
    max_term = max(activations.items(), key=lambda x: x[1])
    return ale_centers[max_term[0]]

# 6) Tek satÄ±r deÄŸerlendirme fonksiyonu
def evaluate_row(row, mfs, method, aggregation="max"):
    rule_strengths = []
    rule_terms = []
    rule_weights = []

    for antecedents, consequent, weight in enhanced_rules:
        if not antecedents:  # default rule
            strength = 0.1
        else:
            if aggregation == "min":
                strength = min(mfs[var][setname](row[var]) for var, setname in antecedents.items())
            elif aggregation == "prod":
                strength = np.prod([mfs[var][setname](row[var]) for var, setname in antecedents.items()])
            else:  # default to max (actually still using min logic)
                strength = min(mfs[var][setname](row[var]) for var, setname in antecedents.items())

        weighted_strength = strength * weight
        rule_strengths.append(weighted_strength)
        rule_terms.append(consequent)

    # AktivasyonlarÄ± hesapla
    activations = {}
    for strength, term in zip(rule_strengths, rule_terms):
        if strength > 0:
            activations[term] = max(activations.get(term, 0), strength)

    # Defuzzification
    if method == "centroid":
        return defuzz_centroid(activations, mfs["ale"])
    elif method == "weighted_avg":
        return defuzz_weighted_average(activations)
    elif method == "max_membership":
        return defuzz_max_membership(activations)
    elif method == "COS":
        return defuzz_center_of_sums(activations, mfs["ale"])
    else:
        return defuzz_weighted_average(activations)


# 7) TÃ¼m kombinasyonlarÄ± test et
def run_combination(mfs, method, aggregation="min"):
    """Bir kombinasyon iÃ§in sonuÃ§larÄ± hesapla"""
    predictions = []
    for _, row in df.iterrows():
        pred = evaluate_row(row, mfs, method, aggregation)
        predictions.append(pred)

    mae = mean_absolute_error(df["ale"], predictions)
    rmse = np.sqrt(mean_squared_error(df["ale"], predictions))
    r2 = r2_score(df["ale"], predictions)

    return mae, rmse, r2, predictions

# 8) TÃ¼m kombinasyonlarÄ± Ã§alÄ±ÅŸtÄ±r ve sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r
print("\n=== FUZZY LOGIC SÄ°STEM SONUÃ‡LARI ===")
print(f"{'Model':<20} {'Method':<12} {'Agg':<5} {'MAE':<8} {'RMSE':<8} {'RÂ²':<8}")
print("-" * 65)

all_results = []
mf_dict = {
    "Optimized_Tri": optimized_triangular,
    "Optimized_Gauss": optimized_gaussian,
    "Hybrid_Optimized": hybrid_optimized,
    "Optimized_Trap": optimized_trapezoidal
}

methods = ["centroid", "weighted_avg", "max_membership","COS"]
aggregations = ["min", "prod"]

best_result = None
best_score = float('inf')

for mf_name, mfs in mf_dict.items():
    for method in methods:
        for agg in aggregations:
            try:
                mae, rmse, r2, preds = run_combination(mfs, method, agg)

                print(f"{mf_name:<20} {method:<12} {agg:<5} {mae:<8.4f} {rmse:<8.4f} {r2:<8.4f}")

                all_results.append({
                    'model': mf_name,
                    'method': method,
                    'aggregation': agg,
                    'mae': mae,
                    'rmse': rmse,
                    'r2': r2,
                    'predictions': preds
                })

                # En iyi modeli takip et (MAE'ye gÃ¶re)
                if mae < best_score:
                    best_score = mae
                    best_result = all_results[-1].copy()

            except Exception as e:
                print(f"{mf_name:<20} {method:<12} {agg:<5} ERROR: {str(e)[:20]}")

print(f"\n=== EN Ä°YÄ° MODEL ===")
if best_result:
    print(f"Model: {best_result['model']}")
    print(f"Method: {best_result['method']}")
    print(f"Aggregation: {best_result['aggregation']}")
    print(f"MAE: {best_result['mae']:.4f}")
    print(f"RMSE: {best_result['rmse']:.4f}")
    print(f"RÂ²: {best_result['r2']:.4f}")

# 9) GÃ¶rselleÅŸtirme
if best_result:

    df_hatalar = df.copy()
    df_hatalar["tahmin"] = best_result["predictions"]
    df_hatalar["hata"] = df_hatalar["tahmin"] - df_hatalar["ale"]
    df_hatalar["mutlak_hata"] = np.abs(df_hatalar["hata"])

    # Hatalara gÃ¶re sÄ±ralama (en bÃ¼yÃ¼k hata en Ã¼stte)
    df_hatalar_sorted = df_hatalar.sort_values("mutlak_hata", ascending=False)

    # En kÃ¶tÃ¼ 10 tahmini yazdÄ±r
    print("\n=== EN HATALI 10 TAHMÄ°N ===")
    print(df_hatalar_sorted[["anchor_ratio", "trans_range", "node_density", "iterations", "ale", "tahmin", "hata", "mutlak_hata"]].head(20))

    plt.figure(figsize=(12, 8))

    # GerÃ§ek vs Tahmin edilen deÄŸerler
    plt.subplot(2, 2, 1)
    plt.scatter(df["ale"], best_result['predictions'], alpha=0.7)
    plt.plot([df["ale"].min(), df["ale"].max()], [df["ale"].min(), df["ale"].max()], 'r--')
    plt.xlabel('GerÃ§ek ALE')
    plt.ylabel('Tahmin Edilen ALE')
    plt.title('GerÃ§ek vs Tahmin Edilen DeÄŸerler')
    plt.grid(True, alpha=0.3)

    # Hata daÄŸÄ±lÄ±mÄ±
    plt.subplot(2, 2, 2)
    errors = np.array(best_result['predictions']) - df["ale"].values
    plt.hist(errors, bins=20, alpha=0.7, edgecolor='black')
    plt.xlabel('Hata (Tahmin - GerÃ§ek)')
    plt.ylabel('Frekans')
    plt.title('Hata DaÄŸÄ±lÄ±mÄ±')
    plt.grid(True, alpha=0.3)

    # Residual plot
    plt.subplot(2, 2, 3)
    plt.scatter(best_result['predictions'], errors, alpha=0.7)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Tahmin Edilen ALE')
    plt.ylabel('Residual')
    plt.title('Residual Plot')
    plt.grid(True, alpha=0.3)

    # Model performansÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±
    plt.subplot(2, 2, 4)
    mae_values = [r['mae'] for r in all_results[:10]]  # Ä°lk 10 model
    model_names = [f"{r['model'][:8]}_{r['method'][:3]}" for r in all_results[:10]]
    plt.bar(range(len(mae_values)), mae_values)
    plt.xlabel('Model')
    plt.ylabel('MAE')
    plt.title('Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±')
    plt.xticks(range(len(model_names)), model_names, rotation=45)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

print(f"\n=== SONUÃ‡ Ã–ZETÄ° ===")
print(f"Toplam {len(all_results)} farklÄ± model kombinasyonu test edildi.")
print(f"En iyi model MAE: {best_score:.4f}")
print("Model veri setinizin Ã¶zelliklerine gÃ¶re optimize edilmiÅŸtir.")

# ðŸ”§ Lineer Regresyon ile EÄŸimi DÃ¼zelt
from sklearn.linear_model import LinearRegression

y_true = df["ale"].values
y_pred = np.array(best_result["predictions"])

reg = LinearRegression().fit(y_pred.reshape(-1, 1), y_true)
y_pred_corrected = reg.predict(y_pred.reshape(-1, 1))

print("\n=== LINEER DÃœZELTME SONRASI ===")
print("EÄŸim katsayÄ±sÄ±:", reg.coef_[0])
print("Bias (kesiÅŸim):", reg.intercept_)
print("MAE:", mean_absolute_error(y_true, y_pred_corrected))
print("RMSE:", np.sqrt(mean_squared_error(y_true, y_pred_corrected)))